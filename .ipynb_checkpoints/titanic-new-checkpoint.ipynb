{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Reading the data","metadata":{}},{"cell_type":"code","source":"train=pd.read_csv(\"/kaggle/input/titanic/train.csv\")\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test=pd.read_csv(\"/kaggle/input/titanic/test.csv\")\ntest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nEDA","metadata":{}},{"cell_type":"code","source":"#let's have information about datasets\ntrain.info()\ntest.info()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of null values for training data\nprint(train.isnull().sum())\ntrain.isnull().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Distribution of null values for test data\nprint(test.isnull().sum())\ntest.isnull().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.nunique()#@unique values for training data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.nunique()#unique values for testing data","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\n\n\n\n\nAnalizing Categorical data","metadata":{}},{"cell_type":"markdown","source":"Age","metadata":{}},{"cell_type":"code","source":"train.Sex.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"Sex\")[\"Survived\"].mean()#it seems gender is going to be  very interesting for our predictions","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"Sex\"],train[\"Survived\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"\nPclass","metadata":{}},{"cell_type":"code","source":"train.Pclass.value_counts()# the distribution for classes of trip","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"Pclass\")[\"Survived\"].mean()#people in 1st class had more chances to survive","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n\npd.crosstab(train[\"Pclass\"],train[\"Survived\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"SibSp","metadata":{}},{"cell_type":"code","source":"train.SibSp.value_counts()#most of people were alone or withouth siblings or spouses","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"SibSp\")[\"Survived\"].mean()#People with 1 or 2 siblings had more chances to survive","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"SibSp\"],train[\"Survived\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Parch","metadata":{}},{"cell_type":"code","source":"train.Parch.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"Parch\"],train[\"Survived\"])#Similar to Sibsp. We have the maximum of chance to survive for a low value of Parch","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"Parch\"],train[\"Survived\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Embarked","metadata":{}},{"cell_type":"code","source":"train.Embarked.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"Embarked\"],train[\"Survived\"])#Values for Embarked in Cherbourg seems better. Let's look at the correlation with Pclass","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"Embarked\"],train[\"Pclass\"])#As we can see the most of Embarked in Cherbourg were in 1st class. They are not equally distributed for this variable","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"Embarked\")[\"Survived\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Quantitative Variable","metadata":{}},{"cell_type":"code","source":"train.describe()#Some variable are more skewed, like Fare","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.corr()# Pclass(negatively) and Fare(positively) seems the more correlated with Age. Sibsp and Parch are correlated as well","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nplt.figure(figsize=(8,6))\nsns.heatmap(train.corr())# we can see it better with the heatmap","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sns.pairplot(train)#let's take a look at the distributions. Many variables looks like categorical even they are numeric\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Creation of new Variables","metadata":{}},{"cell_type":"markdown","source":"Name_length\nThe lenght of the name could mean difference on the status in the society","metadata":{}},{"cell_type":"code","source":"train['Name_length'] = train['Name'].apply(len)\ntest['Name_length'] = test['Name'].apply(len)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_b=train.copy()\ntrain_b","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Log Fare\nWe prefer to use the logarithm of Fare because of the high skewness","metadata":{}},{"cell_type":"code","source":"train[\"log_Fare\"]=np.log1p(train[\"Fare\"])\ntrain.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"log_Fare\"]=np.log1p(test[\"Fare\"])\ntest.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.skew()#As we can see the skewness is reduced with the new variable","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Relatives.\n\nWe count the number of people nearest to the passenger ( Sibsp + Parch)","metadata":{}},{"cell_type":"markdown","source":"Not Alone.\n\nA Variable who distinguuishes who is alone from others","metadata":{}},{"cell_type":"code","source":"data = [train, test]\nfor dataset in data:\n    dataset['relatives'] = dataset['SibSp'] + dataset['Parch']\n    dataset.loc[dataset['relatives'] > 0, 'not_alone'] = 0\n    dataset.loc[dataset['relatives'] == 0, 'not_alone'] = 1\n    dataset['not_alone'] = dataset['not_alone'].astype(int)\ntrain['not_alone'].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"not_alone\"].value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Deck\n\nDistinguishes who has the Deck from others","metadata":{}},{"cell_type":"code","source":"train.Cabin=train.Cabin.fillna(\"Missing\")#We operate on Cabin variable to deal with missings. \ntrain.Cabin","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.Cabin=test.Cabin.fillna(\"Missing\")\ntest.Cabin","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#i create a function for finding the first letter of the cabin\ndef desk (string):\n    prima=string[0]\n    return prima","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"deck\"]=train[\"Cabin\"].apply(desk)\ntrain","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"deck\"]=test[\"Cabin\"].apply(desk)\ntest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"deck\"],train[\"Survived\"])#We can clearly see that who doesn't have a deck had less chances to survive. We can modify Deck in a binary variable ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"deck\")[\"Survived\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Ponte\n\nBinary variable who distinguish who was withouth deck","metadata":{}},{"cell_type":"code","source":"def ponte (string):\n    if string==\"M\":\n        return 0\n    else:\n        return 1\n    \ntrain[\"Ponte\"]=train.deck.apply(ponte)\ntrain.Ponte","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"Ponte\"]=test.deck.apply(ponte)\ntest.Ponte","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train.Ponte,train.Survived)#We can see the influence of this variable","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.info()#We have now more variable ... we have to cut some of them to make a good choice for the model(\"Occam's Razor\"). Except for Deck they are all numeric","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Over_40_Name\n","metadata":{}},{"cell_type":"code","source":"train.sort_values(\"Name_length\").head(20)#this is an aspect to consider i think... but is correlated to gender and Fare as well","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.sort_values(\"Name_length\").tail(20)#With very long name we have an higher percentage of survivors","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.groupby(\"Name_length\")[\"Survived\"].mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def over_40(string):\n    if len(string)>40:\n        return 1\n    else:\n        return 0\n    \ntrain[\"Over40\"]=train[\"Name\"].apply(over_40)\ntest[\"Over40\"]=test[\"Name\"].apply(over_40)\nprint(train[\"Over40\"].value_counts())\nprint(train.groupby(\"Over40\")[\"Survived\"].mean())\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.crosstab(train[\"Over40\"],train[\"Survived\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(train,\"Survived\",index=[\"Sex\"],#For every Gender we have an higher percentage of survivors especially for men(even the sample is little)\n              columns=[\"Over40\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.pivot_table(train,\"Fare\",index=[\"Sex\"],#This could be another aspect correlated with the social status\n               columns=[\"Over40\"])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's see if the last variable can have an impact on the prediction","metadata":{}},{"cell_type":"code","source":"train.corr()#Finally we can see that the new variables are correlated with \"Survived\" we can take them and delete other original variables","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Before to proceed... we have still to manage some missing values","metadata":{}},{"cell_type":"code","source":"train.isnull().mean()# We will impute the median for  Age because is more robust to outliers.. and we will impute the mode for Embarked","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test.isnull().mean()# like below we will impute the median for age and for the few missings for log_Fare( Fare doesn't interest us we will exclude it)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Age\nLet's try to analize one of the most significative variable for our analysis. We can follow more strategies about null values. If we look at the correlations it doesn't seems that Age is significative but after a fast fact checking we knew that a lot of childs were saved... We can choose to make imputation by median or find a correlation between missing values and some general features of the dataset. We could estimate for example with a regression model... or just leave missing and create a dummy variable with classes of Ages","metadata":{}},{"cell_type":"code","source":"#First of all we can try to understand if the distribution of missing reflect the distribution of the overall population\nAge_missing=train[train.Age.isnull()]\nAge_missing.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.describe()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"-We can see that the mean of the survivors is lower( we should test how if a significative difference with a test).\n\n-The class is more unbalanced because (136 on 177 of the missing values travelled in 3rd class).\n\n-Fare is in general lower than in the rest of dataset\n-There is another significative difference about being not alone (75% of people were alone against 60% of the rest of sample)\n- There is finally a significative difference about \"Ponte\" variable. Less persons were in the deck.\n","metadata":{}},{"cell_type":"code","source":"train[\"intAge\"]=int(train.Age)\ntrain.groupby(\"intAge\")[\"Survived\"].mean()\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Age_missing.not_alone.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.not_alone.value_counts()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Age\"]=train[\"Age\"].fillna(train[\"Age\"].median())#Imputation for Age in the train set\ntrain.isnull().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train[\"Embarked\"]=train[\"Embarked\"].fillna(\"S\") # Southampton is the mode for the distribution \ntrain.isnull().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"Age\"]=test[\"Age\"].fillna(test[\"Age\"].median()) # imputation for the median of Age in test set \ntest.isnull().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test[\"log_Fare\"]=test[\"log_Fare\"].fillna(test[\"log_Fare\"].median()) # Imputation for log_Fare in test set\ntest.isnull().mean()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\n\ny = train[\"Survived\"]\n\nfeatures = [ \"Sex\",\"log_Fare\", \"Age\",\"Ponte\",'relatives','not_alone',\"Name_length\",\"Over40\"]\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ny = train[\"Survived\"]\n\nfeatures = [ 'Sex','log_Fare', 'Age','Ponte','not_alone']\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = ['Pclass', 'Sex','log_Fare', 'Age','Ponte','not_alone','Over40']\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\nmodel.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"features = [ 'Sex','log_Fare', 'Age','Ponte','not_alone']\nX = pd.get_dummies(train[features])\nX_test = pd.get_dummies(test[features])\n\n\nmodel = RandomForestClassifier(n_estimators=100, max_depth=5, random_state=0)\ngrid = GridSearchCV(estimator = model, param_grid = {'max_depth': range(2, 6)}, cv = 10)\ngrid.fit(X, y)\npredictions = model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split, GridSearchCV\n#run model\nmodel = RandomForestClassifier(n_estimators = 5, random_state = 0)\ngrid = GridSearchCV(estimator = model, param_grid = {'max_depth': range(2, 6)}, cv = 10)\ngrid.fit(X, y)\n\npredict = grid.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predict})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X, y)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X, y) * 100, 2)\nacc_log","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': Y_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X, y)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X, y) * 100, 2)\nacc_svc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X, y)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X, y) * 100, 2)\nacc_knn","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"perceptron = Perceptron()\nperceptron.fit(X, y)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X,y) * 100, 2)\nacc_perceptron","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X, y)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X,y) * 100, 2)\nacc_linear_svc","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X, y)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X, y) * 100, 2)\nacc_sgd","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X, y)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X, y) * 100, 2)\nacc_decision_tree","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': Y_pred})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(X, y)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X, y)\nacc_random_forest = round(random_forest.score(X,y) * 100, 2)\nacc_random_forest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"random_forest= RandomForestClassifier(n_estimators=100, max_depth=3, random_state=0)\nrandom_forest.fit(X, y)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X, y)\nacc_random_forest = round(random_forest.score(X,y) * 100, 2)\nacc_random_forest","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def evaluate(model, X_test, y_test):\n    predictions = model.predict(y_test)\n    errors = abs(predict - y_test)\n    mape = 100 * np.mean(errors / y_test)\n    accuracy = 100 - mape\n    print('Model Performance')\n    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n    print('Accuracy = {:0.2f}%.'.format(accuracy))\n    \n    return accuracy\n\nmodel = RandomForestClassifier(n_estimators = 5, random_state = 0)\ngrid = GridSearchCV(estimator = model, param_grid = {'max_depth': range(2, 6)}, cv = 10)\ngrid.fit(X, y)\n\npredict = grid.predict(X_test)\nbest_random = grid.best_estimator_\nrandom_accuracy = evaluate(best_random, X, y)                     ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}